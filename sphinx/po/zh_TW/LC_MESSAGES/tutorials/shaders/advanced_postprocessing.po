# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0)
# This file is distributed under the same license as the Godot Engine package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Godot Engine 4.2\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-02-27 19:04+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

msgid "Advanced post-processing"
msgstr "高級後期處理"

msgid "Introduction"
msgstr "前言"

msgid ""
"This tutorial describes an advanced method for post-processing in Godot. In "
"particular, it will explain how to write a post-processing shader that uses "
"the depth buffer. You should already be familiar with post-processing "
"generally and, in particular, with the methods outlined in the :ref:`custom "
"post-processing tutorial <doc_custom_postprocessing>`."
msgstr ""
"本教學描述了一種在 Godot 中進行後期處理的高級方法。值得注意的是，它將解釋如何"
"編寫使用深度緩衝區的後期處理著色器。您應該已經熟悉後期處理，特別是使用:ref:`"
"自訂後期處理教學 <doc_custom_postprocessing>`中介紹的方法。"

msgid ""
"In the previous post-processing tutorial, we rendered the scene to a :ref:"
"`Viewport <class_Viewport>` and then rendered the Viewport in a :ref:"
"`SubViewportContainer <class_SubViewportContainer>` to the main scene. One "
"limitation of this method is that we could not access the depth buffer "
"because the depth buffer is only available in shaders and Viewports do not "
"maintain depth information."
msgstr ""
"在前面的後期處理教學中，我們將場景算繪到了 :ref:`Viewport <class_Viewport>` "
"中，然後將這個 Viewport 在 :ref:`ViewportContainer "
"<class_ViewportContainer>` 中算繪到主場景。這個方法存在一個局限，我們無法存取"
"深度緩衝區，因為深度緩衝區只在空間著色器中可用，Viewport 並不維護深度資訊。"

msgid "Full screen quad"
msgstr "全屏四邊形"

msgid ""
"In the :ref:`custom post-processing tutorial <doc_custom_postprocessing>`, "
"we covered how to use a Viewport to make custom post-processing effects. "
"There are two main drawbacks of using a Viewport:"
msgstr ""
"在:ref:`自訂後期處理教學<doc_custom_postprocessing>`中，我們介紹了如何使用 "
"Viewport 來製作自訂的後期處理特效。使用 Viewport 有兩個主要的缺點："

msgid "The depth buffer cannot be accessed"
msgstr "無法存取深度緩衝區"

msgid "The effect of the post-processing shader is not visible in the editor"
msgstr "在編輯器中看不到後期處理著色器的效果"

msgid ""
"To get around the limitation on using the depth buffer, use a :ref:"
"`MeshInstance3D <class_MeshInstance3D>` with a :ref:`QuadMesh "
"<class_QuadMesh>` primitive. This allows us to use a shader and to access "
"the depth texture of the scene. Next, use a vertex shader to make the quad "
"cover the screen at all times so that the post-processing effect will be "
"applied at all times, including in the editor."
msgstr ""
"要解決使用深度緩衝區的限制，請使用 :ref:`MeshInstance <class_MeshInstance>` "
"並設定 :ref:`QuadMesh <class_QuadMesh>` 像素。這樣我們就可以使用空間著色器，"
"並且可以存取該場景的深度紋理。接下來，請使用頂點著色器讓這個四邊形始終覆蓋螢"
"幕，以便始終應用後期處理效果，包括在編輯器中。"

msgid ""
"First, create a new MeshInstance3D and set its mesh to a QuadMesh. This "
"creates a quad centered at position ``(0, 0, 0)`` with a width and height of "
"``1``. Set the width and height to ``2`` and enable **Flip Faces**. Right "
"now, the quad occupies a position in world space at the origin. However, we "
"want it to move with the camera so that it always covers the entire screen. "
"To do this, we will bypass the coordinate transforms that translate the "
"vertex positions through the difference coordinate spaces and treat the "
"vertices as if they were already in clip space."
msgstr ""
"首先，新建一個 MeshInstance，並將其網格設定為 QuadMesh。這將建立一個以座標 "
"``(0, 0, 0)`` 為中心的四邊形，寬度和高度均為 ``1``。請將其寬度和高度設定為 "
"``2``。現在，這個四邊形在世界空間中佔據了原點的位置；但是，我們希望它能隨著相"
"機的移動而移動，這樣它就能始終覆蓋整個螢幕。為此，我們將繞過座標轉換，該轉換"
"通過不同的座標空間轉換頂點位置，並將頂點視為已位於裁剪空間中。"

msgid ""
"The vertex shader expects coordinates to be output in clip space, which are "
"coordinates ranging from ``-1`` at the left and bottom of the screen to "
"``1`` at the top and right of the screen. This is why the QuadMesh needs to "
"have height and width of ``2``. Godot handles the transform from model to "
"view space to clip space behind the scenes, so we need to nullify the "
"effects of Godot's transformations. We do this by setting the ``POSITION`` "
"built-in to our desired position. ``POSITION`` bypasses the built-in "
"transformations and sets the vertex position directly."
msgstr ""
"頂點著色器希望在裁剪空間中輸出座標，即從螢幕左側和底部的 ``-1`` 到螢幕頂部和"
"右側的 ``1`` 的座標。這就是為什麼 QuadMesh 的高度和寬度需要是 ``2``。Godot 會"
"在幕後處理從模型到視圖空間再到剪輯空間的轉換，所以我們需要使 Godot 的轉換效果"
"無效。我們通過設定內建 ``POSITION`` 到我們想要的座標來做到這一點。"
"``POSITION`` 會繞過內建變換，直接設定頂點座標。"

msgid ""
"Even with this vertex shader, the quad keeps disappearing. This is due to "
"frustum culling, which is done on the CPU. Frustum culling uses the camera "
"matrix and the AABBs of Meshes to determine if the Mesh will be visible "
"*before* passing it to the GPU. The CPU has no knowledge of what we are "
"doing with the vertices, so it assumes the coordinates specified refer to "
"world positions, not clip space positions, which results in Godot culling "
"the quad when we turn away from the center of the scene. In order to keep "
"the quad from being culled, there are a few options:"
msgstr ""
"即使有了這樣的頂點著色器，這個四邊形仍會消失。這是因為視錐剔除的緣故，是在 "
"CPU 上完成的。視錐剔除使用相機矩陣和 Mesh 的 AABB 來確定 Mesh 是否可見，然後"
"再傳遞給 GPU。CPU 不知道我們對頂點做了什麼，所以它認為指定的座標指的是世界座"
"標，而不是裁剪空間的座標，這就導致了 Godot 在我們旋轉、離開場景中心時對四邊形"
"進行剔除。為了防止四邊形被剔除，有這麼幾個選項："

msgid ""
"Add the QuadMesh as a child to the camera, so the camera is always pointed "
"at it"
msgstr "將 QuadMesh 作為子節點新增到相機，這樣相機就會始終指向它"

msgid ""
"Set the Geometry property ``extra_cull_margin`` as large as possible in the "
"QuadMesh"
msgstr "在 QuadMesh 中將幾何屬性 ``extra_cull_margin`` 設定得盡可能大"

msgid ""
"The second option ensures that the quad is visible in the editor, while the "
"first option guarantees that it will still be visible even if the camera "
"moves outside the cull margin. You can also use both options."
msgstr ""
"第二個選項會確保四邊形在編輯器中可見，而第一個選項能夠保證即使相機移出剔除邊"
"緣也它仍可見。您也可以同時使用這兩個選項。"

msgid "Depth texture"
msgstr "深度紋理"

msgid ""
"To read from the depth texture, we first need to create a texture uniform "
"set to the depth buffer by using ``hint_depth_texture``."
msgstr ""
"要讀取深度紋理，我們首先需要使用「hint_depth_texture」來建立一個設定為深度緩"
"衝區的均勻紋理。"

msgid ""
"Once defined, the depth texture can be read with the ``texture()`` function."
msgstr "定義後，可以使用“texture()”函式讀取深度紋理。"

msgid ""
"Similar to accessing the screen texture, accessing the depth texture is only "
"possible when reading from the current viewport. The depth texture cannot be "
"accessed from another viewport to which you have rendered."
msgstr ""
"與存取螢幕紋理類似，存取深度紋理只有在從目前視口讀取時才能進行。深度紋理不能"
"從你已經算繪的另一個視口中存取。"

msgid ""
"The values returned by ``depth_texture`` are between ``0.0`` and ``1.0`` and "
"are nonlinear. When displaying depth directly from the ``depth_texture``, "
"everything will look almost white unless it is very close. This is because "
"the depth buffer stores objects closer to the camera using more bits than "
"those further, so most of the detail in depth buffer is found close to the "
"camera. In order to make the depth value align with world or model "
"coordinates, we need to linearize the value. When we apply the projection "
"matrix to the vertex position, the z value is made nonlinear, so to "
"linearize it, we multiply it by the inverse of the projection matrix, which "
"in Godot, is accessible with the variable ``INV_PROJECTION_MATRIX``."
msgstr ""
"``DEPTH_TEXTURE`` 返回的值介於 ``0`` 和 ``1`` 之間，並且是非線性的。當直接從 "
"``DEPTH_TEXTURE`` 顯示深度時，除非非常接近，否則一切都會看起來幾乎是白色的。"
"這是因為深度緩衝區會使用更多的位元來儲存更靠近相機的物件，因此深度緩衝區中的"
"大部分細節都靠近相機。為了使深度值與世界或模型座標對齊，我們需要將值線性化，"
"當我們將投影矩陣應用於頂點位置時，Z 值是非線性的，所以為了將其線性化，我們將"
"它乘以投影矩陣的逆矩陣，在 Godot 中可以用變數 ``INV_PROJECTION_MATRIX`` 存"
"取。"

msgid ""
"Firstly, take the screen space coordinates and transform them into "
"normalized device coordinates (NDC). NDC run ``-1.0`` to ``1.0`` in ``x`` "
"and ``y`` directions and from ``0.0`` to ``1.0`` in the ``z`` direction when "
"using the Vulkan backend. Reconstruct the NDC using ``SCREEN_UV`` for the "
"``x`` and ``y`` axis, and the depth value for ``z``."
msgstr ""
"首先, 取螢幕空間座標並將其轉換為正規化裝置座標(NDC).NDC從 ``-1`` 到 ``1`` , "
"類似於裁剪空間座標. 使用 ``SCREEN_UV`` 來重建NDC的 ``x`` 和 ``y`` 軸, 以及 "
"``z`` 的深度值."

msgid ""
"This tutorial assumes the use of the Vulkan renderer, which uses NDCs with a "
"Z-range of ``[0.0, 1.0]``. In contrast, OpenGL uses NDCs with a Z-range of "
"``[-1.0, 1.0]``."
msgstr ""
"本教學假設使用 Vulkan 算繪器，它使用 Z 範圍為「[0.0, 1.0]」的 NDC。相較之下，"
"OpenGL 使用 Z 範圍為「[-1.0, 1.0]」的 NDC。"

msgid ""
"Convert NDC to view space by multiplying the NDC by "
"``INV_PROJECTION_MATRIX``. Recall that view space gives positions relative "
"to the camera, so the ``z`` value will give us the distance to the point."
msgstr ""
"通過將NDC乘以 ``INV_PROJECTION_MATRIX`` , 將NDC轉換成視圖空間. 回顧一下, 視圖"
"空間給出了相對於相機的位置, 所以 ``z`` 值將給我們提供到該點的距離."

msgid ""
"Because the camera is facing the negative ``z`` direction, the position will "
"have a negative ``z`` value. In order to get a usable depth value, we have "
"to negate ``view.z``."
msgstr ""
"因為相機是朝向負的 ``z`` 方向的, 所以座標會有一個負的 ``z`` 值. 為了得到一個"
"可用的深度值, 我們必須否定 ``view.z`` ."

msgid ""
"The world position can be constructed from the depth buffer using the "
"following code. Note that the ``INV_VIEW_MATRIX`` is needed to transform the "
"position from view space into world space, so it needs to be passed to the "
"fragment shader with a varying."
msgstr ""
"世界座標可以通過以下程式碼從深度緩衝區建構. 注意 ``CAMERA_MATRIX`` 需要將座標"
"從視圖空間轉換到世界空間, 所以它需要以varying的方式傳遞給片段著色器."

msgid "An optimization"
msgstr "優化"

msgid ""
"You can benefit from using a single large triangle rather than using a full "
"screen quad. The reason for this is explained `here <https://michaldrobot."
"com/2014/04/01/gcn-execution-patterns-in-full-screen-passes>`_. However, the "
"benefit is quite small and only beneficial when running especially complex "
"fragment shaders."
msgstr ""
"您可以使用單個大三角形而不是使用全屏四邊形. 解釋的原因在 `這裡 <https://"
"michaldrobot.com/2014/04/01/gcn-execution-patterns-in-full-screen-"
"passes>`_ . 但是, 這種好處非常小, 只有在運作特別複雜的片段著色器時才有用."

msgid ""
"Set the Mesh in the MeshInstance3D to an :ref:`ArrayMesh <class_ArrayMesh>`. "
"An ArrayMesh is a tool that allows you to easily construct a Mesh from "
"Arrays for vertices, normals, colors, etc."
msgstr ""
"將MeshInstance中的Mesh設定為 :ref:`ArrayMesh <class_ArrayMesh>`. ArrayMesh是"
"一個工具, 允許您從頂點, 法線, 顏色等方便地從陣列建構網格."

msgid "Now, attach a script to the MeshInstance3D and use the following code:"
msgstr "現在, 將腳本附加到MeshInstance並使用以下程式碼:"

msgid ""
"The triangle is specified in normalized device coordinates. Recall, NDC run "
"from ``-1.0`` to ``1.0`` in both the ``x`` and ``y`` directions. This makes "
"the screen ``2`` units wide and ``2`` units tall. In order to cover the "
"entire screen with a single triangle, use a triangle that is ``4`` units "
"wide and ``4`` units tall, double its height and width."
msgstr ""
"三角形在標準化裝置座標中指定. 回想一下,NDC在 ``x`` 和 ``y`` 方向都從 ``-1`` "
"到 ``1`` 運作. 這使得螢幕 ``2`` 單位寬, ``2`` 單位高. 為了用一個三角形覆蓋整"
"個螢幕, 使用一個 ``4`` 單位寬和 ``4`` 單位高的三角形, 高度和寬度加倍."

msgid ""
"Assign the same vertex shader from above and everything should look exactly "
"the same."
msgstr "從上面分配相同的頂點著色器, 所有內容應該看起來完全相同."

#, fuzzy
msgid ""
"The one drawback to using an ArrayMesh over using a QuadMesh is that the "
"ArrayMesh is not visible in the editor because the triangle is not "
"constructed until the scene is run. To get around that, construct a single "
"triangle Mesh in a modeling program and use that in the MeshInstance3D "
"instead."
msgstr ""
"使用ArrayMesh而不是使用QuadMesh的一個缺點是ArrayMesh在編輯器中不可見, 因為在"
"運作場景之前不會建構三角形. 為了解決這個問題, 在建模程式中建構一個三角形"
"Mesh, 然後在MeshInstance中使用它."

msgid "Translation status"
msgstr "翻譯狀態"
